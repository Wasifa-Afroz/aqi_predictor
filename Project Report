Karachi AQI Predictor
Real-Time Air Quality Forecasting

Wasifa Afroz  |  Data Science Project  |  February 2026

Live Dashboard: https://aqipredictor-9vmzkfmxqvlv9svubxwilu.streamlit.app/
 
1. Project Overview
The Karachi AQI Predictor is a complete MLOps system that monitors and forecasts air quality in Karachi, Pakistan. The system collects hourly environmental data via APIs, engineers 62 features, trains separate ML models for 24h/48h/72h forecasts, and serves predictions through an interactive dashboard — operating fully autonomously via GitHub Actions.
Objectives Achieved
•	Automated hourly data collection from OpenWeather API (24 runs/day)
•	Feature engineering pipeline producing 62 time-series features per sample
•	Multi-horizon forecasting with 3 separately trained models (24h, 48h, 72h)
•	Interactive 5-page dashboard deployed on Streamlit Cloud
•	100% automation via GitHub Actions CI/CD — zero manual intervention
Final Results
Metric	Value
Best Model	LightGBM
R² Score (24h)	0.569
RMSE	15.18 AQI points
MAE	11.90 AQI points
Training Samples	4,248+
Historical Data	180+ days
Features	62 engineered features
Forecast Horizons	24h, 48h, 72h
Automation	24 hourly + 1 daily job
Deployment	Streamlit Cloud (live 24/7)

2. Technical Implementation
2.1 Data Collection
•	API: OpenWeather Air Pollution + Weather APIs
•	Location: Karachi, Pakistan (24.8607°N, 67.0011°E)
•	Frequency: Every hour via GitHub Actions cron (0 * * * *)
•	Data fields: AQI, PM2.5, PM10, NO2, SO2, CO, O3, temperature, humidity, pressure, wind speed
2.2 Feature Engineering (62 Features)
•	Time features (6): hour, day, month, day_of_week, is_weekend, week_of_year
•	Lag features (12): aqi_lag_1/2/3/24, pm25_lag_1/2/3/24, temperature_lag_1/2/3/24
•	Rolling statistics (24): mean/std over 3h/6h/12h/24h windows for aqi, pm25, temperature
•	Change rates (4): aqi_change_rate, aqi_change_rate_pct, pm25_change_rate, temp_change_rate
•	Raw measurements (16): current pollutant levels and weather conditions
2.3 Machine Learning Models
Trained 9 models total (3 algorithms × 3 forecast horizons):
•	LightGBM (n_estimators=500, max_depth=20, learning_rate=0.05) — Best performer
•	XGBoost (n_estimators=500, max_depth=8, learning_rate=0.05)
•	Random Forest (n_estimators=300, max_depth=25)
•	Ridge Regression (alpha=1.0) — Baseline
Model	24h R²	48h R²	72h R²	Status
LightGBM	0.569	0.556	0.546	✅ Active (Best)
XGBoost	0.551	0.556	0.552	Available
RandomForest	0.583	0.582	0.583	Available

2.4 Storage & Model Registry
•	Primary storage: MongoDB Atlas (cloud feature store, 4,248+ samples)
•	Model storage: GitHub Actions Artifacts (30-day retention)
•	Local models: model_24h.pkl, model_48h.pkl, model_72h.pkl, scaler.pkl, feature_names.json
2.5 Dashboard (5 Pages)
•	Dashboard: Live AQI, weather conditions, 3-day forecast with trend chart
•	Analytics: Model metrics, SHAP feature importance, 7-day trends, hourly patterns
•	Historical Data: 10-day table with CSV download
•	Model Details: Architecture, hyperparameters, R² scores
•	Health Guide: Mask recommendations, outdoor activity advice by AQI level
 
3. Major Challenges Encountered
Challenge 1: Storage Platform — MongoDB Instead of Hopsworks
Original Plan: Use Hopsworks feature store as demonstrated in MLOps courses.
Problem:
•	Hopsworks free tier requires credit card verification
•	Complex setup process unsuitable for academic projects
•	GitHub Actions integration not straightforward
Solution: Switched to MongoDB Atlas
•	Free tier with no credit card requirement (512MB storage)
•	Better suited for time-series data (document-based storage)
•	Simple authentication via connection string in GitHub Secrets
•	Easier integration with GitHub Actions cloud runners
Outcome: MongoDB proved superior for this use case — simpler to implement and maintain while providing all required functionality.

Challenge 2: GitHub File Size Limit (117MB Models)
Problem:
•	Trained models totaled 117MB (model_24h.pkl + model_48h.pkl + model_72h.pkl)
•	GitHub rejects commits with files >100MB
•	Error: 'File models/best_model_optimized.pkl is 117.52 MB; exceeds limit'
Solution:
•	Added models/*.pkl to .gitignore — models excluded from Git
•	Used GitHub Actions Artifacts for model versioning (30-day retention)
•	Implemented auto-training on Streamlit Cloud deployment
•	If models missing, app trains automatically on first run using MongoDB data
Outcome: Clean separation — code in Git, models in artifacts + cloud auto-training.

Challenge 3: Random Predictions on Dashboard Refresh
Problem:
•	Dashboard showed different 48h/72h predictions every time user clicked refresh
•	Example: Refresh 1: [152, 148, 145] → Refresh 2: [155, 151, 149] (different!)
•	Root cause: Used np.random.uniform() to extrapolate from 24h predictions
Solution:
•	Trained 3 completely separate models (not 1 model + random extrapolation)
•	Replaced: pred_48h = pred_24h * np.random.uniform(0.95, 1.10)  # ❌
•	With: pred_48h = model_48h.predict(features)[0]  # ✅
Outcome: Predictions now deterministic — same input always produces same output. Dashboard shows consistent forecasts across refreshes.

Challenge 4: Streamlit Cloud 'Models Not Found' Error
Problem:
•	Dashboard worked perfectly locally but failed on Streamlit Cloud
•	Error: 'Models not found! Please train models first.'
•	Cause: Models excluded by .gitignore, never uploaded to GitHub
Solution:
•	Implemented auto-training function in app.py startup code
•	On first Streamlit Cloud visit, app automatically:
•	  - Checks if models exist (model_24h.pkl, etc.)
•	  - If missing, loads data from MongoDB
•	  - Runs training_pipeline.py (5-10 minutes)
•	  - Saves models locally (persists in cloud container)
•	Subsequent visits: models already exist, loads instantly
Outcome: Zero-configuration deployment — models train automatically on first run, no manual setup required.

Challenge 5: GitHub Actions Workflow Not Triggering
Problem:
•	Hourly automation stopped working — no data collection
•	Root cause: YAML file had documentation text mixed into code
•	Invalid separator and markdown documentation broke workflow parsing
Solution:
•	Rewrote automated_pipeline.yml cleanly from scratch
•	Separated into clean sections: data collection job, training job, manual trigger
•	Updated deprecated upload-artifact@v3 → upload-artifact@v4
•	Fixed incorrect conditional variable names
Outcome: Automation fully restored — 24 hourly collections + 1 daily training run consistently.
 
4. Deployment & Automation
GitHub Actions Pipeline
Job	Trigger	PKT Time	Duration
Data Collection	cron: 0 * * * *	Every hour :00	~20 seconds
Model Training	cron: 0 18 * * *	2:00 AM daily	~8 minutes
Manual Trigger	workflow_dispatch	On-demand	Variable

Deployment Stack
•	Dashboard: Streamlit Cloud (https://aqipredictor-9vmzkfmxqvlv9svubxwilu.streamlit.app/)
•	Storage: MongoDB Atlas (cloud database)
•	CI/CD: GitHub Actions (free tier)
•	Model Registry: GitHub Actions Artifacts (30-day retention)
•	Auto-training: Built into app.py for first-time deployment
5. Key Learnings
•	MongoDB Atlas > Hopsworks for simple time-series projects — easier setup, better GitHub Actions integration, no credit card required
•	Git is for code, not models — use artifacts/cloud storage for large binary files (>100MB)
•	Train separate models per horizon — never extrapolate with random values; predictions must be deterministic
•	Auto-training solves deployment challenges — if models missing, train automatically from MongoDB data
•	YAML is strict — documentation belongs in comments (#), not as raw text blocks
•	Feature engineering is crucial — lag and rolling features are the strongest predictors
•	Real data accumulation takes time — R² will improve naturally as dataset grows from 180 to 270+ days
6. Future Improvements
•	Accumulate more data — 270+ days will improve R² from 0.569 to ~0.70
•	Add LSTM/Transformer model for better temporal sequence modeling
•	Expand to multiple Pakistan cities (Lahore, Islamabad, Peshawar)
•	Implement SMS/email alerts when AQI exceeds user-defined threshold
•	Build mobile-responsive Progressive Web App (PWA)
•	Integrate additional features: traffic data, industrial activity, wind direction
7. Conclusion
The Karachi AQI Predictor successfully demonstrates a complete MLOps pipeline from data collection through deployment. Every component — API integration, feature engineering, model training, automation, and dashboard deployment — is implemented and operational. The system runs autonomously 24/7 with zero manual intervention required.
Major challenges (storage platform selection, file size limits, prediction consistency, cloud deployment) were solved systematically, resulting in a production-ready system. The current R² of 0.569 represents solid performance given 180 days of data, and will improve organically as the dataset grows.
The project provides real value to Karachi residents by delivering consistent, data-driven AQI forecasts with health recommendations — fulfilling the core objective of helping people make informed decisions about air quality.

Wasifa Afroz  |  Data Science Project  |  February 2026
